# From Loops to Launches: Matrix Multiplication on the GPU

*Your second CUDA kernelâ€”and the foundation of deep learning*

---

## Introduction

In the [previous post](./vector_addition_medium_blog.md), we wrote our first CUDA kernel: vector addition. Each thread computed one element: `C[i] = A[i] + B[i]`. Simple, parallel, and a great starting point.

Now we're stepping up to **matrix multiplication**â€”the workhorse of linear algebra and the beating heart of deep learning. Every neural network forward pass, every transformer attention layer, every convolutionâ€”at the core, they're all matrix multiplications.

Here's the problem: given two matrices **A** (M Ã— K) and **B** (K Ã— N), compute their product **C** (M Ã— N):

```
C[row][col] = Î£ (A[row][k] Ã— B[k][col])  for k = 0 to K-1
```

Each element of C is a **dot product** of a row from A and a column from B.

On a CPU, this is an O(M Ã— N Ã— K) operation with three nested loops. For large matrices (say, 4096 Ã— 4096), that's **68 billion** multiply-add operations. Even at 100 GFLOPS, that's nearly a second per multiplication.

A GPU can do this in **milliseconds**â€”if you structure the computation correctly.

---

## Why Matrix Multiplication is Perfect for GPUs

Matrix multiplication has three properties that make it GPU-friendly:

1. **Massive parallelism**: Each element of C can be computed independently
2. **Regular memory access**: Rows and columns have predictable patterns
3. **High arithmetic intensity**: Lots of math operations per byte loaded (when optimized)

The challenge? Each output element requires reading an entire row of A and an entire column of B. That's a lot of memory trafficâ€”and memory bandwidth is the GPU's bottleneck.

> ğŸ’¡ **Key insight:** Naive matrix multiplication is **memory-bound**. The real art of GPU optimization is reducing redundant memory loads through **tiling** and **shared memory**. We'll start simple, then show the optimized version.

---

## The Thread Hierarchy for 2D Problems

In vector addition, we used a 1D grid of 1D blocks. For matrices, we use a **2D grid of 2D blocks**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     GRID (gridDim.x Ã— gridDim.y)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚Block    â”‚ â”‚Block    â”‚ â”‚Block    â”‚ â”‚Block    â”‚ ...            â”‚
â”‚  â”‚(0,0)    â”‚ â”‚(1,0)    â”‚ â”‚(2,0)    â”‚ â”‚(3,0)    â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚Block    â”‚ â”‚Block    â”‚ â”‚Block    â”‚ â”‚Block    â”‚ ...            â”‚
â”‚  â”‚(0,1)    â”‚ â”‚(1,1)    â”‚ â”‚(2,1)    â”‚ â”‚(3,1)    â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚  ...                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Each **block** covers a tile of the output matrix C. Each **thread** within a block computes one element of C.

### The 2D Index Formula

```cpp
int row = blockIdx.y * blockDim.y + threadIdx.y;
int col = blockIdx.x * blockDim.x + threadIdx.x;
```

This is the 2D equivalent of our 1D formula `i = blockIdx.x * blockDim.x + threadIdx.x`.

---

## Visual: The Complete Thread Hierarchy

Here's how everything maps together (recreate this as a diagram):

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           CUDA MATRIX MULTIPLICATION KERNEL - THREAD HIERARCHY                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   Matrix A (MÃ—K)      Matrix B (KÃ—N)      Matrix C (MÃ—N)                      â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â•‘
â•‘   â”‚           â”‚       â”‚           â”‚       â”‚ â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â” â”‚               â•‘
â•‘   â”‚    M      â”‚   Ã—   â”‚     K     â”‚   =   â”‚ â”‚Blockâ”‚Blockâ”‚...â”‚ â”‚               â•‘
â•‘   â”‚    Ã—      â”‚       â”‚     Ã—     â”‚       â”‚ â”‚(0,0)â”‚(1,0)â”‚   â”‚ â”‚  â† GRID       â•‘
â•‘   â”‚    K      â”‚       â”‚     N     â”‚       â”‚ â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¤ â”‚               â•‘
â•‘   â”‚           â”‚       â”‚           â”‚       â”‚ â”‚Blockâ”‚Blockâ”‚...â”‚ â”‚               â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ â”‚(0,1)â”‚(1,1)â”‚   â”‚ â”‚               â•‘
â•‘                                           â”‚ â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”˜ â”‚               â•‘
â•‘                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â•‘
â•‘                                                                               â•‘
â•‘   Each cell in grid = 1 Block                                                 â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘   BLOCK DETAIL (blockDim.x=16, blockDim.y=16 = 256 threads)                   â•‘
â•‘                                                                               â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â•‘
â•‘   â”‚ Warp 0 (threads 0-31)â”‚ Warp 1 (threads 32-63)â”‚                            â•‘
â•‘   â”‚  threadIdx.x: 0-15   â”‚  threadIdx.x: 0-15    â”‚                            â•‘
â•‘   â”‚  threadIdx.y: 0-1    â”‚  threadIdx.y: 2-3     â”‚                            â•‘
â•‘   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                               â•‘
â•‘   â”‚ Warp 2 (threads 64-95)â”‚ Warp 3 (threads 96-127)â”‚                          â•‘
â•‘   â”‚  threadIdx.x: 0-15   â”‚  threadIdx.x: 0-15    â”‚                            â•‘
â•‘   â”‚  threadIdx.y: 4-5    â”‚  threadIdx.y: 6-7     â”‚                            â•‘
â•‘   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                               â•‘
â•‘   â”‚ Warp 4 (128-159)    â”‚ Warp 5 (160-191)     â”‚                              â•‘
â•‘   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                               â•‘
â•‘   â”‚ Warp 6 (192-223)    â”‚ Warp 7 (224-255)     â”‚                              â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â•‘
â•‘                                                                               â•‘
â•‘   8 Warps Ã— 32 threads = 256 threads/block                                    â•‘
â•‘   (32 threads execute in lockstep - SIMT)                                     â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘   THREAD COMPUTATION (single element of C)                                    â•‘
â•‘                                                                               â•‘
â•‘   // Global thread indices                                                    â•‘
â•‘   row = blockIdx.y * blockDim.y + threadIdx.y                                 â•‘
â•‘   col = blockIdx.x * blockDim.x + threadIdx.x                                 â•‘
â•‘                                                                               â•‘
â•‘   // Dot product for C[row][col]                                              â•‘
â•‘   float sum = 0.0f;                                                           â•‘
â•‘   for (int k = 0; k < K; k++)                                                 â•‘
â•‘       sum += A[row*K + k] * B[k*N + col];                                     â•‘
â•‘   C[row*N + col] = sum;                                                       â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘   HIERARCHY SUMMARY                                    KERNEL LAUNCH          â•‘
â•‘                                                                               â•‘
â•‘   GPU                                                  dim3 block(16, 16);    â•‘
â•‘    â””â”€â”€ Grid                                            dim3 grid(N/16, M/16); â•‘
â•‘         â”œâ”€â”€ Block[0,0] Block[0,1] ...                                         â•‘
â•‘         â”œâ”€â”€ Block[1,0] Block[1,1] ...                  matmul<<<grid, block>>>â•‘
â•‘         â”‚    â””â”€â”€ Warp 0: threads 0-31                      (A, B, C);         â•‘
â•‘         â”‚    â””â”€â”€ Warp 1: threads 32-63                                        â•‘
â•‘         â”‚    â””â”€â”€ ... (8 warps total)                   // Total threads =     â•‘
â•‘         â”‚         â””â”€â”€ Thread: C[i][j]                  //   M Ã— N             â•‘
â•‘         â””â”€â”€ ...                                                               â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘   KEY CONCEPTS:                                                               â•‘
â•‘   1. Grid covers output matrix C - each block computes a TILE_SIZEÃ—TILE_SIZE  â•‘
â•‘   2. Block = 256 threads (16Ã—16) executing on same SM, sharing resources      â•‘
â•‘   3. Warp = 32 threads executing SIMT (same instruction, multiple threads)    â•‘
â•‘   4. Thread computes one element: C[row][col] = dot(A[row,:], B[:,col])       â•‘
â•‘   5. Memory coalescing: adjacent threads access adjacent memory for efficiencyâ•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## The Naive Kernel: One Thread Per Output Element

Let's start with the simplest approach: each thread computes one element of C by performing a full dot product.

```cpp
__global__ void matmulNaive(const float* A, const float* B, float* C,
                            int M, int N, int K)
{
    // Calculate row and column for this thread
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    
    // Boundary check
    if (row < M && col < N)
    {
        float sum = 0.0f;
        
        // Dot product: row of A Ã— column of B
        for (int k = 0; k < K; k++)
        {
            sum += A[row * K + k] * B[k * N + col];
        }
        
        C[row * N + col] = sum;
    }
}
```

### Launch Configuration

```cpp
#define BLOCK_SIZE 16

dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);  // 256 threads per block
dim3 gridDim((N + BLOCK_SIZE - 1) / BLOCK_SIZE, 
             (M + BLOCK_SIZE - 1) / BLOCK_SIZE);  // Ceiling division

matmulNaive<<<gridDim, blockDim>>>(d_A, d_B, d_C, M, N, K);
```

### Why 16Ã—16?

- 16 Ã— 16 = 256 threads, a common sweet spot
- Divides evenly into warps (256 / 32 = 8 warps)
- Good balance between occupancy and register usage

---

## The Problem with Naive: Memory Bandwidth

Let's analyze the memory access pattern:

For a matrix multiplication of size 1024 Ã— 1024 Ã— 1024:
- Each thread reads **1024 elements from A** (one row)
- Each thread reads **1024 elements from B** (one column)
- Total reads per thread: 2048 floats = 8 KB
- Total threads: 1024 Ã— 1024 = 1 million
- Total memory reads: **8 TB** of data movement!

But waitâ€”matrix A is only 4 MB and B is only 4 MB. We're reading the same data **millions of times**.

> âš ï¸ **The bottleneck:** In naive matmul, every thread re-reads the same rows and columns from global memory. Global memory is slow (~500 GB/s on modern GPUs), so we're completely memory-bound.

---

## The Solution: Tiled Matrix Multiplication with Shared Memory

The key insight: **threads in the same block can share data**.

CUDA provides **shared memory**â€”a fast, programmer-managed cache that's shared among all threads in a block. Instead of each thread loading its own data from global memory, we:

1. **Load a tile** of A and B into shared memory (one load per thread)
2. **Synchronize** all threads in the block
3. **Compute** partial results using the fast shared memory
4. **Repeat** for all tiles along the K dimension

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TILED MATRIX MULTIPLICATION                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚  Matrix A                    Matrix B                   Matrix C       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    â”‚Tileâ”‚    â”‚   â”‚       â”‚         â”‚        â”‚       â”‚          â”‚   â”‚
â”‚  â”‚    â”‚ 0  â”‚    â”‚   â”‚       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”‚       â”‚   Tile   â”‚   â”‚
â”‚  â”‚â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”‚   Ã—   â”‚  Tile 0 â”‚ Tile 1 â”‚   =   â”‚  Output  â”‚   â”‚
â”‚  â”‚    â”‚Tileâ”‚    â”‚   â”‚       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”‚       â”‚          â”‚   â”‚
â”‚  â”‚    â”‚ 1  â”‚    â”‚   â”‚       â”‚         â”‚        â”‚       â”‚          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                        â”‚
â”‚  Step 1: Load Tile 0 of A and Tile 0 of B into shared memory          â”‚
â”‚  Step 2: Compute partial dot products (all threads, fast shared mem)  â”‚
â”‚  Step 3: Synchronize                                                   â”‚
â”‚  Step 4: Load Tile 1 of A and Tile 1 of B into shared memory          â”‚
â”‚  Step 5: Accumulate more partial dot products                          â”‚
â”‚  ...repeat for all tiles...                                            â”‚
â”‚  Step N: Write final result to C                                       â”‚
â”‚                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Tiled Kernel

```cpp
#define TILE_SIZE 16

__global__ void matmulTiled(const float* __restrict__ A, 
                            const float* __restrict__ B, 
                            float* __restrict__ C,
                            int M, int N, int K)
{
    // Shared memory for tiles
    __shared__ float tileA[TILE_SIZE][TILE_SIZE];
    __shared__ float tileB[TILE_SIZE][TILE_SIZE];
    
    // Thread's position in the output matrix
    int row = blockIdx.y * TILE_SIZE + threadIdx.y;
    int col = blockIdx.x * TILE_SIZE + threadIdx.x;
    
    float sum = 0.0f;
    
    // Loop over tiles along the K dimension
    for (int t = 0; t < (K + TILE_SIZE - 1) / TILE_SIZE; t++)
    {
        // Load tile from A: A[row * K + (t*TILE + threadIdx.x)]
        // Adjacent threads (varying threadIdx.x) load adjacent floats â†’ COALESCED
        int aCol = t * TILE_SIZE + threadIdx.x;
        if (row < M && aCol < K)
            tileA[threadIdx.y][threadIdx.x] = A[row * K + aCol];
        else
            tileA[threadIdx.y][threadIdx.x] = 0.0f;
        
        // Load tile from B: B[bRow * N + col], where col = blockIdx.x*TILE + threadIdx.x
        // Adjacent threads (varying threadIdx.x) load adjacent floats â†’ COALESCED
        int bRow = t * TILE_SIZE + threadIdx.y;
        if (bRow < K && col < N)
            tileB[threadIdx.y][threadIdx.x] = B[bRow * N + col];
        else
            tileB[threadIdx.y][threadIdx.x] = 0.0f;
        
        // Wait for all threads to finish loading
        __syncthreads();
        
        // Compute partial dot product for this tile
        // TILE_SIZE is compile-time constant, so compiler can unroll this loop
        #pragma unroll
        for (int k = 0; k < TILE_SIZE; k++)
        {
            sum += tileA[threadIdx.y][k] * tileB[k][threadIdx.x];
        }
        
        // Wait before loading next tile (prevent data race)
        __syncthreads();
    }
    
    // Write result
    if (row < M && col < N)
    {
        C[row * N + col] = sum;
    }
}
```

> ğŸ’¡ **Why `__restrict__`?** This keyword tells the compiler that `A`, `B`, and `C` don't overlap in memory, enabling more aggressive optimizations like caching loads via L1/texture cache (LDG instructions).
```

### Why Tiling Works

| Aspect | Naive | Tiled |
|--------|-------|-------|
| Global memory reads per element | 2K | 2K / TILE_SIZE |
| Memory reuse | None | TILE_SIZE Ã— reuse |
| Shared memory usage | 0 | TILE_SIZEÂ² Ã— 2 Ã— 4 bytes |
| Achieved bandwidth | ~10% peak | ~60-80% peak |

For TILE_SIZE = 16, we reduce global memory traffic by **16Ã—**.

### Why This Loading Pattern is Coalesced

Memory coalescing is crucial for performance. Let's verify our loads are coalesced:

**Loading A:** `A[row * K + (t * TILE_SIZE + threadIdx.x)]`
- `row` is the same for all threads in a warp (same `blockIdx.y` and `threadIdx.y`)
- `threadIdx.x` varies from 0-15 across threads
- Result: Adjacent threads access `A[row*K + 0]`, `A[row*K + 1]`, ... `A[row*K + 15]` â†’ **Coalesced!**

**Loading B:** `B[(t * TILE_SIZE + threadIdx.y) * N + col]` where `col = blockIdx.x * TILE_SIZE + threadIdx.x`
- `bRow` is the same for threads with the same `threadIdx.y`
- `col` varies with `threadIdx.x`
- Result: Adjacent threads access `B[bRow*N + 0]`, `B[bRow*N + 1]`, ... â†’ **Coalesced!**

> âš ï¸ **Common mistake:** If you accidentally used `threadIdx.y` as the inner dimension for loading B (like `B[row * N + threadIdx.y]`), you'd get strided access with a stride of `N`â€”terrible for performance!

---

## The Complete Program

> âš ï¸ **Note:** This example uses `new` for simplicity. For benchmarking, use `cudaMallocHost` (pinned memory) to avoid the driver's implicit copy from pageable to pinned memory. See the benchmark code in the repository for production-style `CUDA_CHECK` macros and pinned memory.

```cpp
#include <cuda_runtime.h>
#include <cstdio>
#include <cstdlib>
#include <cmath>

#define TILE_SIZE 16

// Tiled matrix multiplication kernel
__global__ void matmulTiled(const float* __restrict__ A, 
                            const float* __restrict__ B, 
                            float* __restrict__ C,
                            int M, int N, int K)
{
    __shared__ float tileA[TILE_SIZE][TILE_SIZE];
    __shared__ float tileB[TILE_SIZE][TILE_SIZE];
    
    int row = blockIdx.y * TILE_SIZE + threadIdx.y;
    int col = blockIdx.x * TILE_SIZE + threadIdx.x;
    
    float sum = 0.0f;
    
    for (int t = 0; t < (K + TILE_SIZE - 1) / TILE_SIZE; t++)
    {
        int aCol = t * TILE_SIZE + threadIdx.x;
        if (row < M && aCol < K)
            tileA[threadIdx.y][threadIdx.x] = A[row * K + aCol];
        else
            tileA[threadIdx.y][threadIdx.x] = 0.0f;
        
        int bRow = t * TILE_SIZE + threadIdx.y;
        if (bRow < K && col < N)
            tileB[threadIdx.y][threadIdx.x] = B[bRow * N + col];
        else
            tileB[threadIdx.y][threadIdx.x] = 0.0f;
        
        __syncthreads();
        
        #pragma unroll
        for (int k = 0; k < TILE_SIZE; k++)
            sum += tileA[threadIdx.y][k] * tileB[k][threadIdx.x];
        
        __syncthreads();
    }
    
    if (row < M && col < N)
        C[row * N + col] = sum;
}

// CPU reference implementation
void matmulCPU(const float* A, const float* B, float* C, int M, int N, int K)
{
    for (int i = 0; i < M; i++)
    {
        for (int j = 0; j < N; j++)
        {
            float sum = 0.0f;
            for (int k = 0; k < K; k++)
                sum += A[i * K + k] * B[k * N + j];
            C[i * N + j] = sum;
        }
    }
}

int main()
{
    // Matrix dimensions
    int M = 1024;  // A is MÃ—K
    int K = 1024;  // B is KÃ—N
    int N = 1024;  // C is MÃ—N
    
    size_t sizeA = M * K * sizeof(float);
    size_t sizeB = K * N * sizeof(float);
    size_t sizeC = M * N * sizeof(float);
    
    // Allocate host memory (pinned for consistent transfer timing)
    // Note: For a simple demo, you can use new float[], but benchmarks
    // should use pinned memory to avoid implicit pageableâ†’pinned copies
    float *h_A, *h_B, *h_C, *h_C_ref;
    cudaMallocHost(&h_A, sizeA);
    cudaMallocHost(&h_B, sizeB);
    cudaMallocHost(&h_C, sizeC);
    h_C_ref = new float[M * N];  // CPU reference doesn't need pinned
    
    // Initialize matrices with random values
    for (int i = 0; i < M * K; i++) h_A[i] = (float)(rand() % 100) / 100.0f;
    for (int i = 0; i < K * N; i++) h_B[i] = (float)(rand() % 100) / 100.0f;
    
    // Allocate device memory
    float *d_A, *d_B, *d_C;
    cudaMalloc(&d_A, sizeA);
    cudaMalloc(&d_B, sizeB);
    cudaMalloc(&d_C, sizeC);
    
    // Copy to device
    cudaMemcpy(d_A, h_A, sizeA, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, h_B, sizeB, cudaMemcpyHostToDevice);
    
    // Launch kernel
    dim3 blockDim(TILE_SIZE, TILE_SIZE);
    dim3 gridDim((N + TILE_SIZE - 1) / TILE_SIZE, 
                 (M + TILE_SIZE - 1) / TILE_SIZE);
    
    matmulTiled<<<gridDim, blockDim>>>(d_A, d_B, d_C, M, N, K);
    cudaDeviceSynchronize();
    
    // Copy result back
    cudaMemcpy(h_C, d_C, sizeC, cudaMemcpyDeviceToHost);
    
    // CPU reference
    matmulCPU(h_A, h_B, h_C_ref, M, N, K);
    
    // Verify
    float maxError = 0.0f;
    for (int i = 0; i < M * N; i++)
    {
        float error = fabs(h_C[i] - h_C_ref[i]);
        if (error > maxError) maxError = error;
    }
    
    printf("Matrix size: %d Ã— %d Ã— %d\n", M, K, N);
    printf("Max error: %e\n", maxError);
    printf("Result: %s\n", maxError < 1e-3 ? "PASS" : "FAIL");
    
    // Cleanup
    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);
    cudaFreeHost(h_A); cudaFreeHost(h_B); cudaFreeHost(h_C);
    delete[] h_C_ref;
    
    return 0;
}
```

---

## Benchmarking: Naive vs Tiled vs cuBLAS

Let's measure the real performance difference.

### Benchmark Setup

| Component | Details |
|-----------|---------|
| **GPU** | NVIDIA GTX 1650 Max-Q (14 SMs, CC 7.5) |
| **Memory** | 4.29 GB GDDR6, 160 GB/s bandwidth |
| **Timing** | CUDA Events, averaged over 10 runs after warmup |
| **Memory Type** | Pinned host memory (cudaMallocHost) |
| **Comparison** | Naive kernel, Tiled kernel (TILE=16), cuBLAS |

### Results (1024 Ã— 1024 Matrices)

| Implementation | Time (ms) | GFLOPS | Speedup |
|----------------|-----------|--------|---------|
| **GPU Naive** | 15.90 ms | 135.09 | baseline |
| **GPU Tiled (TILE=16)** | 8.31 ms | 258.33 | 1.9Ã— |
| **cuBLAS** | 0.82 ms | 2616.21 | 19.4Ã— |

### Scaling Across Matrix Sizes

| Size | GPU Naive | GPU Tiled | cuBLAS | Tiled Speedup |
|------|-----------|-----------|--------|---------------|
| 256Ã—256 | 0.25 ms (135 GFLOPS) | 0.16 ms (207 GFLOPS) | 0.06 ms (602 GFLOPS) | 1.5Ã— |
| 512Ã—512 | 2.01 ms (134 GFLOPS) | 1.23 ms (218 GFLOPS) | 0.27 ms (997 GFLOPS) | 1.6Ã— |
| 1024Ã—1024 | 15.90 ms (135 GFLOPS) | 8.31 ms (258 GFLOPS) | 0.82 ms (2616 GFLOPS) | 1.9Ã— |
| 2048Ã—2048 | 75.71 ms (227 GFLOPS) | 49.81 ms (345 GFLOPS) | 6.43 ms (2670 GFLOPS) | 1.5Ã— |

> ğŸ’¡ **GFLOPS calculation:** For M=N=K=1024, total FLOPs = 2 Ã— 1024Â³ â‰ˆ 2.15 billion. Divide by time in seconds.

### Key Observations

1. **Tiled is ~2Ã— faster than naive** â€” shared memory reduces global memory traffic
2. **cuBLAS is 10Ã— faster than our tiled** â€” it uses advanced optimizations (register blocking, vectorized loads, double buffering, warp-level primitives)
3. **cuBLAS achieves 2.6 TFLOPS** â€” that's impressive for a laptop GPU with ~4.8 TFLOPS theoretical peak!

---

## Understanding the Memory Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GPU MEMORY HIERARCHY                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Fastest    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     REGISTERS       â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ ~20 TB/s                 â”‚ â”‚
â”‚  â”‚  (per thread)       â”‚              â”‚ Private to each thread   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚            â”‚                                                        â”‚
â”‚            â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   SHARED MEMORY     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ ~10 TB/s                 â”‚ â”‚
â”‚  â”‚  (per block)        â”‚              â”‚ Shared by all threads    â”‚ â”‚
â”‚  â”‚  __shared__ float   â”‚              â”‚ in a block (48-164 KB)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚            â”‚                                                        â”‚
â”‚            â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    L2 CACHE         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ ~2-4 TB/s                â”‚ â”‚
â”‚  â”‚  (shared by all)    â”‚              â”‚ Automatic caching        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚            â”‚                                                        â”‚
â”‚            â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Slowest    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   GLOBAL MEMORY     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ ~500 GB/s (HBM2)         â”‚ â”‚
â”‚  â”‚  (device VRAM)      â”‚              â”‚ Visible to all threads   â”‚ â”‚
â”‚  â”‚  cudaMalloc'd data  â”‚              â”‚ 4-80 GB                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PCIe Bus (~32 GB/s) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚    HOST MEMORY      â”‚  System RAM (CPU side)                     â”‚
â”‚  â”‚  (cudaMemcpy src)   â”‚                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why tiling works:** We move data from slow global memory (500 GB/s) to fast shared memory (10+ TB/s), then reuse it many times.

---

## Common Pitfalls

### 1. Forgetting `__syncthreads()`

```cpp
// WRONG: Race condition!
tileA[threadIdx.y][threadIdx.x] = A[...];
tileB[threadIdx.y][threadIdx.x] = B[...];
// Some threads start computing before others finish loading
for (int k = 0; k < TILE_SIZE; k++) ...
```

**Fix:** Always synchronize after loading shared memory and before the next load.

### 2. Bank Conflicts in Shared Memory

Shared memory is divided into 32 banks. If multiple threads access the same bank (but different addresses), accesses are serialized.

```cpp
// Potential bank conflict with column-major access
tileA[k][threadIdx.y]  // Threads in a warp hit same bank
```

**Fix:** Pad shared memory or transpose access pattern.

**Why our kernel has NO bank conflicts:**

```cpp
// In the compute loop:
sum += tileA[threadIdx.y][k] * tileB[k][threadIdx.x];
```

- `tileA[threadIdx.y][k]`: All threads in a warp have the same `threadIdx.y` (within a row of the warp). They all read the **same address** â†’ This is a **broadcast**, not a conflict!
- `tileB[k][threadIdx.x]`: Threads have different `threadIdx.x` (0-15). They access different columns â†’ Each thread hits a **different bank** (assuming TILE_SIZE=16 divides evenly into 32 banks).

> ğŸ’¡ **Bank conflict rule:** Same bank, different address = conflict. Same address = broadcast (free). Different banks = parallel access (free).

### 3. Non-Coalesced Global Memory Access

```cpp
// BAD: Strided access (threads read non-adjacent addresses)
A[threadIdx.x * K + col]  // Stride of K between threads

// GOOD: Coalesced access (adjacent threads read adjacent addresses)  
A[row * K + threadIdx.x]  // Stride of 1 between threads
```

---

## What's Next: Advanced Optimizations

Our tiled kernel is good, but cuBLAS is still 3Ã— faster. Here's what the pros do:

1. **Register tiling**: Each thread computes multiple outputs, reducing shared memory traffic
2. **Vectorized loads**: Use `float4` to load 4 floats at once
3. **Double buffering**: Overlap loading the next tile with computing the current tile
4. **Warp-level primitives**: `wmma` for Tensor Cores (Volta and newer)

These optimizations are beyond beginner level, but understanding them helps appreciate why libraries like cuBLAS and cuDNN exist.

---

## Conclusion

You've now written your second CUDA kernelâ€”and one of the most important algorithms in computing:

1. âœ… **2D grids and blocks** for matrix problems
2. âœ… **Naive kernel**: simple but memory-bound
3. âœ… **Tiled kernel**: uses shared memory for 5-6Ã— speedup
4. âœ… **Memory hierarchy**: registers â†’ shared â†’ L2 â†’ global
5. âœ… **Why libraries win**: cuBLAS uses advanced optimizations we didn't cover

### The Bigger Picture

Matrix multiplication is the foundation of:
- **Deep learning**: Every layer is a matmul (or batched matmul)
- **Computer graphics**: Transformations, projections
- **Scientific computing**: Simulations, linear solvers
- **Recommendation systems**: Embedding lookups

Understanding GPU matmul helps you understand why AI runs on GPUsâ€”and why NVIDIA is worth a trillion dollars.

---

## ğŸ§ª Challenge: Experiment with TILE_SIZE

Before moving on, try this experiment:

1. **Change `TILE_SIZE` from 16 to 32**
2. **Recompile and run the benchmark**
3. **Observe what happens to performance**

```cpp
#define TILE_SIZE 32  // Try this!
```

**Questions to consider:**
- Does performance go up or down?
- Why might larger tiles hurt performance?

<details>
<summary>ğŸ’¡ Click for hints</summary>

**Shared memory usage:** `TILE_SIZE=32` means `32Ã—32Ã—2Ã—4 = 8 KB` of shared memory per block (vs 2 KB for TILE_SIZE=16).

**Threads per block:** `32Ã—32 = 1024` threads, the maximum for most GPUs.

**Occupancy:** Larger shared memory usage means fewer blocks can run concurrently on each SM. This reduces **occupancy** (the ratio of active warps to maximum warps).

**Register pressure:** More threads = more register demand. If you exceed the register file, you get **register spilling** to slow local memory.

**The tradeoff:** Larger tiles reduce global memory traffic but hurt occupancy. The optimal TILE_SIZE depends on your GPU's resources. For GTX 1650, TILE_SIZE=16 is often the sweet spot.

</details>

---

## Further Reading

- [CUDA C++ Programming Guide - Shared Memory](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#shared-memory)
- [CUTLASS: CUDA Templates for Linear Algebra](https://github.com/NVIDIA/cutlass)
- [How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance](https://siboehm.com/articles/22/CUDA-MMM)

---

*If you found this helpful, give it a clap ğŸ‘ and follow for more CUDA tutorials.*

---

*Code from this post is available at: [github.com/ajkumar-13/Learning-Cuda](https://github.com/ajkumar-13/Learning-Cuda)*
